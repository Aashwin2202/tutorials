.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:


.. code-block:: default

    from functools import partial
    import numpy as np
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.tune import CLIReporter
    from ray.tune.schedulers import ASHAScheduler







Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.


.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform)

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform)

        return trainset, testset







Configurable neural network
---------------------------
We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:


.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(-1, 16 * 5 * 5)
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x







The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.
As you can guess, the ``config`` parameter will receive the hyperparameters we would like to
train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies
the directory where we load and store the data, so multiple runs can share the same data source.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    if checkpoint_dir:
        model_state, optimizer_state = torch.load(
            os.path.join(checkpoint_dir, "checkpoint"))
        net.load_state_dict(model_state)
        optimizer.load_state_dict(optimizer_state)

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    with tune.checkpoint_dir(epoch) as checkpoint_dir:
        path = os.path.join(checkpoint_dir, "checkpoint")
        torch.save((net.state_dict(), optimizer.state_dict()), path)

    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:


.. code-block:: default



    def train_cifar(config, checkpoint_dir=None, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        if checkpoint_dir:
            model_state, optimizer_state = torch.load(
                os.path.join(checkpoint_dir, "checkpoint"))
            net.load_state_dict(model_state)
            optimizer.load_state_dict(optimizer_state)

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs])

        trainloader = torch.utils.data.DataLoader(
            train_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)
        valloader = torch.utils.data.DataLoader(
            val_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)

        for epoch in range(10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print("[%d, %5d] loss: %.3f" % (epoch + 1, i + 1,
                                                    running_loss / epoch_steps))
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            with tune.checkpoint_dir(epoch) as checkpoint_dir:
                path = os.path.join(checkpoint_dir, "checkpoint")
                torch.save((net.state_dict(), optimizer.state_dict()), path)

            tune.report(loss=(val_loss / val_steps), accuracy=correct / total)
        print("Finished Training")







As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:


.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2)

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total







The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.sample_from()`` function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:


.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16])
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2)
        reporter = CLIReporter(
            # parameter_columns=["l1", "l2", "lr", "batch_size"],
            metric_columns=["loss", "accuracy", "training_iteration"])
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
            progress_reporter=reporter)

        best_trial = result.get_best_trial("loss", "min", "last")
        print("Best trial config: {}".format(best_trial.config))
        print("Best trial final validation loss: {}".format(
            best_trial.last_result["loss"]))
        print("Best trial final validation accuracy: {}".format(
            best_trial.last_result["accuracy"]))

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint_dir = best_trial.checkpoint.value
        model_state, optimizer_state = torch.load(os.path.join(
            best_checkpoint_dir, "checkpoint"))
        best_trained_model.load_state_dict(model_state)

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +---------------------+----------+-------+--------------+------+------+-------------+
    | Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |
    |---------------------+----------+-------+--------------+------+------+-------------|
    | DEFAULT_2a0e1_00000 | RUNNING  |       |           16 |  128 |   32 | 0.0147561   |
    | DEFAULT_2a0e1_00001 | PENDING  |       |            4 |  128 |  256 | 0.00299773  |
    | DEFAULT_2a0e1_00002 | PENDING  |       |            2 |    4 |    4 | 0.00054935  |
    | DEFAULT_2a0e1_00003 | PENDING  |       |            4 |  128 |   16 | 0.0157397   |
    | DEFAULT_2a0e1_00004 | PENDING  |       |           16 |   16 |   16 | 0.00930339  |
    | DEFAULT_2a0e1_00005 | PENDING  |       |            2 |  128 |   16 | 0.00221886  |
    | DEFAULT_2a0e1_00006 | PENDING  |       |            4 |   64 |   32 | 0.0359852   |
    | DEFAULT_2a0e1_00007 | PENDING  |       |            4 |  128 |    4 | 0.000369892 |
    | DEFAULT_2a0e1_00008 | PENDING  |       |            2 |    4 |  128 | 0.000102931 |
    | DEFAULT_2a0e1_00009 | PENDING  |       |            4 |  256 |   16 | 0.0430959   |
    +---------------------+----------+-------+--------------+------+------+-------------+


    [2m[36m(pid=1439)[0m Files already downloaded and verified
    [2m[36m(pid=1488)[0m Files already downloaded and verified
    [2m[36m(pid=1483)[0m Files already downloaded and verified
    [2m[36m(pid=1477)[0m Files already downloaded and verified
    [2m[36m(pid=1476)[0m Files already downloaded and verified
    [2m[36m(pid=1474)[0m Files already downloaded and verified
    [2m[36m(pid=1486)[0m Files already downloaded and verified
    [2m[36m(pid=1458)[0m Files already downloaded and verified
    [2m[36m(pid=1482)[0m Files already downloaded and verified
    [2m[36m(pid=1448)[0m Files already downloaded and verified
    [2m[36m(pid=1439)[0m Files already downloaded and verified
    [2m[36m(pid=1488)[0m Files already downloaded and verified
    [2m[36m(pid=1483)[0m Files already downloaded and verified
    [2m[36m(pid=1477)[0m Files already downloaded and verified
    [2m[36m(pid=1476)[0m Files already downloaded and verified
    [2m[36m(pid=1474)[0m Files already downloaded and verified
    [2m[36m(pid=1486)[0m Files already downloaded and verified
    [2m[36m(pid=1458)[0m Files already downloaded and verified
    [2m[36m(pid=1482)[0m Files already downloaded and verified
    [2m[36m(pid=1448)[0m Files already downloaded and verified
    [2m[36m(pid=1486)[0m [1,  2000] loss: 2.288
    [2m[36m(pid=1477)[0m [1,  2000] loss: 2.305
    [2m[36m(pid=1482)[0m [1,  2000] loss: 2.150
    [2m[36m(pid=1483)[0m [1,  2000] loss: 2.306
    [2m[36m(pid=1488)[0m [1,  2000] loss: 2.015
    [2m[36m(pid=1476)[0m [1,  2000] loss: 2.208
    [2m[36m(pid=1448)[0m [1,  2000] loss: 2.321
    [2m[36m(pid=1458)[0m [1,  2000] loss: 2.328
    [2m[36m(pid=1439)[0m [1,  2000] loss: 1.776
    [2m[36m(pid=1474)[0m [1,  2000] loss: 1.777
    [2m[36m(pid=1486)[0m [1,  4000] loss: 1.080
    [2m[36m(pid=1477)[0m [1,  4000] loss: 1.151
    [2m[36m(pid=1482)[0m [1,  4000] loss: 0.961
    [2m[36m(pid=1483)[0m [1,  4000] loss: 1.122
    [2m[36m(pid=1488)[0m [1,  4000] loss: 0.861
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.4165
      date: 2021-09-27_19-22-19
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 1.6584835968017577
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 27.318493843078613
      time_this_iter_s: 27.318493843078613
      time_total_s: 27.318493843078613
      timestamp: 1632770539
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 9.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.6584835968017577
    Resources requested: 20.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00000 | RUNNING  |                 |           16 |  128 |   32 | 0.0147561   |         |            |                      |
    | DEFAULT_2a0e1_00001 | RUNNING  |                 |            4 |  128 |  256 | 0.00299773  |         |            |                      |
    | DEFAULT_2a0e1_00002 | RUNNING  |                 |            2 |    4 |    4 | 0.00054935  |         |            |                      |
    | DEFAULT_2a0e1_00003 | RUNNING  |                 |            4 |  128 |   16 | 0.0157397   |         |            |                      |
    | DEFAULT_2a0e1_00004 | RUNNING  | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.65848 |     0.4165 |                    1 |
    | DEFAULT_2a0e1_00005 | RUNNING  |                 |            2 |  128 |   16 | 0.00221886  |         |            |                      |
    | DEFAULT_2a0e1_00006 | RUNNING  |                 |            4 |   64 |   32 | 0.0359852   |         |            |                      |
    | DEFAULT_2a0e1_00007 | RUNNING  |                 |            4 |  128 |    4 | 0.000369892 |         |            |                      |
    | DEFAULT_2a0e1_00008 | RUNNING  |                 |            2 |    4 |  128 | 0.000102931 |         |            |                      |
    | DEFAULT_2a0e1_00009 | RUNNING  |                 |            4 |  256 |   16 | 0.0430959   |         |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_2a0e1_00000:
      accuracy: 0.4101
      date: 2021-09-27_19-22-19
      done: false
      experiment_id: e41413128b1a4713a8af0edb08fa79c3
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 1.6301149280548095
      node_ip: 172.17.0.2
      pid: 1439
      should_checkpoint: true
      time_since_restore: 27.547205686569214
      time_this_iter_s: 27.547205686569214
      time_total_s: 27.547205686569214
      timestamp: 1632770539
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00000
  
    [2m[36m(pid=1448)[0m [1,  4000] loss: 1.161
    [2m[36m(pid=1476)[0m [1,  4000] loss: 1.089
    [2m[36m(pid=1458)[0m [1,  4000] loss: 1.163
    [2m[36m(pid=1486)[0m [1,  6000] loss: 0.690
    [2m[36m(pid=1477)[0m [1,  6000] loss: 0.767
    [2m[36m(pid=1482)[0m [1,  6000] loss: 0.604
    [2m[36m(pid=1483)[0m [1,  6000] loss: 0.716
    [2m[36m(pid=1488)[0m [1,  6000] loss: 0.537
    [2m[36m(pid=1448)[0m [1,  6000] loss: 0.774
    [2m[36m(pid=1476)[0m [1,  6000] loss: 0.760
    [2m[36m(pid=1474)[0m [2,  2000] loss: 1.489
    [2m[36m(pid=1439)[0m [2,  2000] loss: 1.510
    [2m[36m(pid=1486)[0m [1,  8000] loss: 0.498
    [2m[36m(pid=1477)[0m [1,  8000] loss: 0.575
    [2m[36m(pid=1482)[0m [1,  8000] loss: 0.435
    [2m[36m(pid=1458)[0m [1,  6000] loss: 0.775
    [2m[36m(pid=1483)[0m [1,  8000] loss: 0.518
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.475
      date: 2021-09-27_19-22-39
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 2
      loss: 1.4563178117752076
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 47.97611713409424
      time_this_iter_s: 20.657623291015625
      time_total_s: 47.97611713409424
      timestamp: 1632770559
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 9.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4563178117752076 | Iter 1.000: -1.6442992624282837
    Resources requested: 20.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00000 | RUNNING  | 172.17.0.2:1439 |           16 |  128 |   32 | 0.0147561   | 1.63011 |     0.4101 |                    1 |
    | DEFAULT_2a0e1_00001 | RUNNING  |                 |            4 |  128 |  256 | 0.00299773  |         |            |                      |
    | DEFAULT_2a0e1_00002 | RUNNING  |                 |            2 |    4 |    4 | 0.00054935  |         |            |                      |
    | DEFAULT_2a0e1_00003 | RUNNING  |                 |            4 |  128 |   16 | 0.0157397   |         |            |                      |
    | DEFAULT_2a0e1_00004 | RUNNING  | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.45632 |     0.475  |                    2 |
    | DEFAULT_2a0e1_00005 | RUNNING  |                 |            2 |  128 |   16 | 0.00221886  |         |            |                      |
    | DEFAULT_2a0e1_00006 | RUNNING  |                 |            4 |   64 |   32 | 0.0359852   |         |            |                      |
    | DEFAULT_2a0e1_00007 | RUNNING  |                 |            4 |  128 |    4 | 0.000369892 |         |            |                      |
    | DEFAULT_2a0e1_00008 | RUNNING  |                 |            2 |    4 |  128 | 0.000102931 |         |            |                      |
    | DEFAULT_2a0e1_00009 | RUNNING  |                 |            4 |  256 |   16 | 0.0430959   |         |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1488)[0m [1,  8000] loss: 0.388
    Result for DEFAULT_2a0e1_00000:
      accuracy: 0.4498
      date: 2021-09-27_19-22-40
      done: true
      experiment_id: e41413128b1a4713a8af0edb08fa79c3
      hostname: a8f4394d0f82
      iterations_since_restore: 2
      loss: 1.5467039808273315
      node_ip: 172.17.0.2
      pid: 1439
      should_checkpoint: true
      time_since_restore: 48.912198305130005
      time_this_iter_s: 21.36499261856079
      time_total_s: 48.912198305130005
      timestamp: 1632770560
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 2a0e1_00000
  
    [2m[36m(pid=1448)[0m [1,  8000] loss: 0.581
    [2m[36m(pid=1476)[0m [1,  8000] loss: 0.578
    [2m[36m(pid=1486)[0m [1, 10000] loss: 0.390
    [2m[36m(pid=1477)[0m [1, 10000] loss: 0.459
    [2m[36m(pid=1482)[0m [1, 10000] loss: 0.343
    [2m[36m(pid=1458)[0m [1,  8000] loss: 0.582
    [2m[36m(pid=1483)[0m [1, 10000] loss: 0.398
    [2m[36m(pid=1488)[0m [1, 10000] loss: 0.301
    [2m[36m(pid=1486)[0m [1, 12000] loss: 0.314
    [2m[36m(pid=1448)[0m [1, 10000] loss: 0.465
    [2m[36m(pid=1477)[0m [1, 12000] loss: 0.377
    [2m[36m(pid=1474)[0m [3,  2000] loss: 1.413
    [2m[36m(pid=1482)[0m [1, 12000] loss: 0.284
    [2m[36m(pid=1476)[0m [1, 10000] loss: 0.462
    Result for DEFAULT_2a0e1_00007:
      accuracy: 0.2397
      date: 2021-09-27_19-22-56
      done: true
      experiment_id: 610833d1b32b472ba03a8792d24e2d0a
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 1.9562242109298706
      node_ip: 172.17.0.2
      pid: 1483
      should_checkpoint: true
      time_since_restore: 64.91072988510132
      time_this_iter_s: 64.91072988510132
      time_total_s: 64.91072988510132
      timestamp: 1632770576
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00007
  
    == Status ==
    Memory usage on this node: 8.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.5015108963012695 | Iter 1.000: -1.6584835968017577
    Resources requested: 18.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (9 RUNNING, 1 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    |                 |            4 |  128 |  256 | 0.00299773  |         |            |                      |
    | DEFAULT_2a0e1_00002 | RUNNING    |                 |            2 |    4 |    4 | 0.00054935  |         |            |                      |
    | DEFAULT_2a0e1_00003 | RUNNING    |                 |            4 |  128 |   16 | 0.0157397   |         |            |                      |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.45632 |     0.475  |                    2 |
    | DEFAULT_2a0e1_00005 | RUNNING    |                 |            2 |  128 |   16 | 0.00221886  |         |            |                      |
    | DEFAULT_2a0e1_00006 | RUNNING    |                 |            4 |   64 |   32 | 0.0359852   |         |            |                      |
    | DEFAULT_2a0e1_00007 | RUNNING    | 172.17.0.2:1483 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | RUNNING    |                 |            2 |    4 |  128 | 0.000102931 |         |            |                      |
    | DEFAULT_2a0e1_00009 | RUNNING    |                 |            4 |  256 |   16 | 0.0430959   |         |            |                      |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.4334
      date: 2021-09-27_19-22-57
      done: false
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 1.531858487868309
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 65.60904026031494
      time_this_iter_s: 65.60904026031494
      time_total_s: 65.60904026031494
      timestamp: 1632770577
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00001
  
    Result for DEFAULT_2a0e1_00006:
      accuracy: 0.1035
      date: 2021-09-27_19-22-59
      done: true
      experiment_id: 5fc01c5cfc85417698f3c0e8c796a115
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 2.3211022354125976
      node_ip: 172.17.0.2
      pid: 1448
      should_checkpoint: true
      time_since_restore: 67.60867857933044
      time_this_iter_s: 67.60867857933044
      time_total_s: 67.60867857933044
      timestamp: 1632770579
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00006
  
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.4911
      date: 2021-09-27_19-22-59
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 3
      loss: 1.4141911527633666
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 68.18954157829285
      time_this_iter_s: 20.21342444419861
      time_total_s: 68.18954157829285
      timestamp: 1632770579
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 2a0e1_00004
  
    [2m[36m(pid=1486)[0m [1, 14000] loss: 0.264
    [2m[36m(pid=1477)[0m [1, 14000] loss: 0.309
    Result for DEFAULT_2a0e1_00003:
      accuracy: 0.1035
      date: 2021-09-27_19-23-01
      done: true
      experiment_id: 699830e62bb54fbfbe252886aeb6f792
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 2.3194027680397036
      node_ip: 172.17.0.2
      pid: 1476
      should_checkpoint: true
      time_since_restore: 69.99140644073486
      time_this_iter_s: 69.99140644073486
      time_total_s: 69.99140644073486
      timestamp: 1632770581
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00003
  
    == Status ==
    Memory usage on this node: 7.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.5015108963012695 | Iter 1.000: -1.8073539038658142
    Resources requested: 14.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.53186 |     0.4334 |                    1 |
    | DEFAULT_2a0e1_00002 | RUNNING    |                 |            2 |    4 |    4 | 0.00054935  |         |            |                      |
    | DEFAULT_2a0e1_00003 | RUNNING    | 172.17.0.2:1476 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.41419 |     0.4911 |                    3 |
    | DEFAULT_2a0e1_00005 | RUNNING    |                 |            2 |  128 |   16 | 0.00221886  |         |            |                      |
    | DEFAULT_2a0e1_00008 | RUNNING    |                 |            2 |    4 |  128 | 0.000102931 |         |            |                      |
    | DEFAULT_2a0e1_00009 | RUNNING    |                 |            4 |  256 |   16 | 0.0430959   |         |            |                      |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1458)[0m [1, 10000] loss: 0.466
    [2m[36m(pid=1482)[0m [1, 14000] loss: 0.234
    [2m[36m(pid=1488)[0m [2,  2000] loss: 1.453
    [2m[36m(pid=1486)[0m [1, 16000] loss: 0.227
    [2m[36m(pid=1477)[0m [1, 16000] loss: 0.260
    Result for DEFAULT_2a0e1_00009:
      accuracy: 0.0965
      date: 2021-09-27_19-23-08
      done: true
      experiment_id: e274b6ed40684aeab9a1c40ec0502929
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 2.3171820987701417
      node_ip: 172.17.0.2
      pid: 1458
      should_checkpoint: true
      time_since_restore: 76.96513152122498
      time_this_iter_s: 76.96513152122498
      time_total_s: 76.96513152122498
      timestamp: 1632770588
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00009
  
    == Status ==
    Memory usage on this node: 7.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.5015108963012695 | Iter 1.000: -1.9562242109298706
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.53186 |     0.4334 |                    1 |
    | DEFAULT_2a0e1_00002 | RUNNING    |                 |            2 |    4 |    4 | 0.00054935  |         |            |                      |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.41419 |     0.4911 |                    3 |
    | DEFAULT_2a0e1_00005 | RUNNING    |                 |            2 |  128 |   16 | 0.00221886  |         |            |                      |
    | DEFAULT_2a0e1_00008 | RUNNING    |                 |            2 |    4 |  128 | 0.000102931 |         |            |                      |
    | DEFAULT_2a0e1_00009 | RUNNING    | 172.17.0.2:1458 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1482)[0m [1, 16000] loss: 0.204
    [2m[36m(pid=1474)[0m [4,  2000] loss: 1.372
    [2m[36m(pid=1486)[0m [1, 18000] loss: 0.198
    [2m[36m(pid=1488)[0m [2,  4000] loss: 0.707
    [2m[36m(pid=1477)[0m [1, 18000] loss: 0.222
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.4885
      date: 2021-09-27_19-23-18
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 4
      loss: 1.4310033589363098
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 86.41795253753662
      time_this_iter_s: 18.228410959243774
      time_total_s: 86.41795253753662
      timestamp: 1632770598
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 6.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.5015108963012695 | Iter 1.000: -1.9562242109298706
    Resources requested: 10.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.53186 |     0.4334 |                    1 |
    | DEFAULT_2a0e1_00002 | RUNNING    |                 |            2 |    4 |    4 | 0.00054935  |         |            |                      |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.431   |     0.4885 |                    4 |
    | DEFAULT_2a0e1_00005 | RUNNING    |                 |            2 |  128 |   16 | 0.00221886  |         |            |                      |
    | DEFAULT_2a0e1_00008 | RUNNING    |                 |            2 |    4 |  128 | 0.000102931 |         |            |                      |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1482)[0m [1, 18000] loss: 0.185
    [2m[36m(pid=1486)[0m [1, 20000] loss: 0.175
    [2m[36m(pid=1477)[0m [1, 20000] loss: 0.196
    [2m[36m(pid=1488)[0m [2,  6000] loss: 0.473
    [2m[36m(pid=1482)[0m [1, 20000] loss: 0.164
    [2m[36m(pid=1474)[0m [5,  2000] loss: 1.350
    [2m[36m(pid=1488)[0m [2,  8000] loss: 0.347
    Result for DEFAULT_2a0e1_00002:
      accuracy: 0.3146
      date: 2021-09-27_19-23-34
      done: false
      experiment_id: 381f03d6c0e4496b826116a5777165c0
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 1.7263863590687514
      node_ip: 172.17.0.2
      pid: 1486
      should_checkpoint: true
      time_since_restore: 102.53317260742188
      time_this_iter_s: 102.53317260742188
      time_total_s: 102.53317260742188
      timestamp: 1632770614
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00002
  
    == Status ==
    Memory usage on this node: 6.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.5015108963012695 | Iter 1.000: -1.841305284999311
    Resources requested: 10.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.53186 |     0.4334 |                    1 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.72639 |     0.3146 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.431   |     0.4885 |                    4 |
    | DEFAULT_2a0e1_00005 | RUNNING    |                 |            2 |  128 |   16 | 0.00221886  |         |            |                      |
    | DEFAULT_2a0e1_00008 | RUNNING    |                 |            2 |    4 |  128 | 0.000102931 |         |            |                      |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_2a0e1_00008:
      accuracy: 0.2751
      date: 2021-09-27_19-23-34
      done: true
      experiment_id: 1f9fe1f3d6454e86b64d14e3d8124003
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 1.940256399321556
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 103.08925747871399
      time_this_iter_s: 103.08925747871399
      time_total_s: 103.08925747871399
      timestamp: 1632770614
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00008
  
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.5204
      date: 2021-09-27_19-23-36
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 5
      loss: 1.3644970433235168
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 104.68266034126282
      time_this_iter_s: 18.264707803726196
      time_total_s: 104.68266034126282
      timestamp: 1632770616
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 2a0e1_00004
  
    Result for DEFAULT_2a0e1_00005:
      accuracy: 0.4209
      date: 2021-09-27_19-23-37
      done: false
      experiment_id: f67f66bf17f94dd09f0a1d1ca7fab0bb
      hostname: a8f4394d0f82
      iterations_since_restore: 1
      loss: 1.577022869822383
      node_ip: 172.17.0.2
      pid: 1482
      should_checkpoint: true
      time_since_restore: 106.01885843276978
      time_this_iter_s: 106.01885843276978
      time_total_s: 106.01885843276978
      timestamp: 1632770617
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 2a0e1_00005
  
    [2m[36m(pid=1486)[0m [2,  2000] loss: 1.744
    [2m[36m(pid=1488)[0m [2, 10000] loss: 0.275
    [2m[36m(pid=1482)[0m [2,  2000] loss: 1.607
    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.4856
      date: 2021-09-27_19-23-48
      done: false
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 2
      loss: 1.4388224743008613
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 116.59178447723389
      time_this_iter_s: 50.982744216918945
      time_total_s: 116.59178447723389
      timestamp: 1632770628
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 2a0e1_00001
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.4563178117752076 | Iter 1.000: -1.8333213791951537
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.43882 |     0.4856 |                    2 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.72639 |     0.3146 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.3645  |     0.5204 |                    5 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1474)[0m [6,  2000] loss: 1.332
    [2m[36m(pid=1486)[0m [2,  4000] loss: 0.869
    [2m[36m(pid=1482)[0m [2,  4000] loss: 0.790
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.5181
      date: 2021-09-27_19-23-54
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 6
      loss: 1.3910182417869568
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 122.67743277549744
      time_this_iter_s: 17.99477243423462
      time_total_s: 122.67743277549744
      timestamp: 1632770634
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.4563178117752076 | Iter 1.000: -1.8333213791951537
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.43882 |     0.4856 |                    2 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.72639 |     0.3146 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.39102 |     0.5181 |                    6 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1486)[0m [2,  6000] loss: 0.572
    [2m[36m(pid=1488)[0m [3,  2000] loss: 1.319
    [2m[36m(pid=1482)[0m [2,  6000] loss: 0.532
    [2m[36m(pid=1486)[0m [2,  8000] loss: 0.426
    [2m[36m(pid=1488)[0m [3,  4000] loss: 0.657
    [2m[36m(pid=1474)[0m [7,  2000] loss: 1.317
    [2m[36m(pid=1482)[0m [2,  8000] loss: 0.402
    [2m[36m(pid=1486)[0m [2, 10000] loss: 0.332
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.5171
      date: 2021-09-27_19-24-12
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 7
      loss: 1.4068411449432372
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 140.4962146282196
      time_this_iter_s: 17.818781852722168
      time_total_s: 140.4962146282196
      timestamp: 1632770652
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.4563178117752076 | Iter 1.000: -1.8333213791951537
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.43882 |     0.4856 |                    2 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.72639 |     0.3146 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.40684 |     0.5171 |                    7 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1488)[0m [3,  6000] loss: 0.440
    [2m[36m(pid=1482)[0m [2, 10000] loss: 0.312
    [2m[36m(pid=1486)[0m [2, 12000] loss: 0.274
    [2m[36m(pid=1488)[0m [3,  8000] loss: 0.328
    [2m[36m(pid=1482)[0m [2, 12000] loss: 0.268
    [2m[36m(pid=1474)[0m [8,  2000] loss: 1.315
    [2m[36m(pid=1486)[0m [2, 14000] loss: 0.234
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.5114
      date: 2021-09-27_19-24-30
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 8
      loss: 1.3964984920024872
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 158.35169386863708
      time_this_iter_s: 17.85547924041748
      time_total_s: 158.35169386863708
      timestamp: 1632770670
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.4563178117752076 | Iter 1.000: -1.8333213791951537
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.43882 |     0.4856 |                    2 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.72639 |     0.3146 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.3965  |     0.5114 |                    8 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1488)[0m [3, 10000] loss: 0.265
    [2m[36m(pid=1482)[0m [2, 14000] loss: 0.225
    [2m[36m(pid=1486)[0m [2, 16000] loss: 0.203
    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.5323
      date: 2021-09-27_19-24-37
      done: false
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 3
      loss: 1.3449715276747942
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 165.82623744010925
      time_this_iter_s: 49.234452962875366
      time_total_s: 165.82623744010925
      timestamp: 1632770677
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 2a0e1_00001
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.4563178117752076 | Iter 1.000: -1.8333213791951537
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.34497 |     0.5323 |                    3 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.72639 |     0.3146 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.3965  |     0.5114 |                    8 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1482)[0m [2, 16000] loss: 0.199
    [2m[36m(pid=1486)[0m [2, 18000] loss: 0.179
    [2m[36m(pid=1474)[0m [9,  2000] loss: 1.293
    [2m[36m(pid=1488)[0m [4,  2000] loss: 1.251
    [2m[36m(pid=1482)[0m [2, 18000] loss: 0.176
    [2m[36m(pid=1486)[0m [2, 20000] loss: 0.161
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.508
      date: 2021-09-27_19-24-47
      done: false
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 9
      loss: 1.411844254875183
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 176.03569769859314
      time_this_iter_s: 17.684003829956055
      time_total_s: 176.03569769859314
      timestamp: 1632770687
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.4563178117752076 | Iter 1.000: -1.8333213791951537
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.34497 |     0.5323 |                    3 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.72639 |     0.3146 |                    1 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.41184 |     0.508  |                    9 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1482)[0m [2, 20000] loss: 0.157
    [2m[36m(pid=1488)[0m [4,  4000] loss: 0.641
    Result for DEFAULT_2a0e1_00002:
      accuracy: 0.3902
      date: 2021-09-27_19-24-57
      done: true
      experiment_id: 381f03d6c0e4496b826116a5777165c0
      hostname: a8f4394d0f82
      iterations_since_restore: 2
      loss: 1.5974287983179092
      node_ip: 172.17.0.2
      pid: 1486
      should_checkpoint: true
      time_since_restore: 186.32995510101318
      time_this_iter_s: 83.79678249359131
      time_total_s: 186.32995510101318
      timestamp: 1632770697
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 2a0e1_00002
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.5015108963012695 | Iter 1.000: -1.8333213791951537
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.34497 |     0.5323 |                    3 |
    | DEFAULT_2a0e1_00002 | RUNNING    | 172.17.0.2:1486 |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.41184 |     0.508  |                    9 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1474)[0m [10,  2000] loss: 1.312
    [2m[36m(pid=1488)[0m [4,  6000] loss: 0.423
    Result for DEFAULT_2a0e1_00004:
      accuracy: 0.5245
      date: 2021-09-27_19-25-05
      done: true
      experiment_id: 6dffd2e88db74d4dbcf0a22caf7965ec
      hostname: a8f4394d0f82
      iterations_since_restore: 10
      loss: 1.3923472019195557
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 193.72858715057373
      time_this_iter_s: 17.69288945198059
      time_total_s: 193.72858715057373
      timestamp: 1632770705
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: 2a0e1_00004
  
    == Status ==
    Memory usage on this node: 5.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.4310033589363098 | Iter 2.000: -1.5015108963012695 | Iter 1.000: -1.8333213791951537
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.34497 |     0.5323 |                    3 |
    | DEFAULT_2a0e1_00004 | RUNNING    | 172.17.0.2:1474 |           16 |   16 |   16 | 0.00930339  | 1.39235 |     0.5245 |                   10 |
    | DEFAULT_2a0e1_00005 | RUNNING    | 172.17.0.2:1482 |            2 |  128 |   16 | 0.00221886  | 1.57702 |     0.4209 |                    1 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00002 | TERMINATED |                 |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_2a0e1_00005:
      accuracy: 0.402
      date: 2021-09-27_19-25-05
      done: true
      experiment_id: f67f66bf17f94dd09f0a1d1ca7fab0bb
      hostname: a8f4394d0f82
      iterations_since_restore: 2
      loss: 1.6391212827880868
      node_ip: 172.17.0.2
      pid: 1482
      should_checkpoint: true
      time_since_restore: 193.73526215553284
      time_this_iter_s: 87.71640372276306
      time_total_s: 193.73526215553284
      timestamp: 1632770705
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 2a0e1_00005
  
    [2m[36m(pid=1488)[0m [4,  8000] loss: 0.319
    [2m[36m(pid=1488)[0m [4, 10000] loss: 0.259
    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.5343
      date: 2021-09-27_19-25-25
      done: false
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 4
      loss: 1.3571617676720023
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 213.89325261116028
      time_this_iter_s: 48.067015171051025
      time_total_s: 213.89325261116028
      timestamp: 1632770725
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 2a0e1_00001
  
    == Status ==
    Memory usage on this node: 4.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.394082563304156 | Iter 2.000: -1.5467039808273315 | Iter 1.000: -1.8333213791951537
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.35716 |     0.5343 |                    4 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00002 | TERMINATED |                 |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00004 | TERMINATED |                 |           16 |   16 |   16 | 0.00930339  | 1.39235 |     0.5245 |                   10 |
    | DEFAULT_2a0e1_00005 | TERMINATED |                 |            2 |  128 |   16 | 0.00221886  | 1.63912 |     0.402  |                    2 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1488)[0m [5,  2000] loss: 1.194
    [2m[36m(pid=1488)[0m [5,  4000] loss: 0.614
    [2m[36m(pid=1488)[0m [5,  6000] loss: 0.414
    [2m[36m(pid=1488)[0m [5,  8000] loss: 0.318
    [2m[36m(pid=1488)[0m [5, 10000] loss: 0.255
    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.5337
      date: 2021-09-27_19-26-12
      done: false
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 5
      loss: 1.4150864756792785
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 260.94604992866516
      time_this_iter_s: 47.05279731750488
      time_total_s: 260.94604992866516
      timestamp: 1632770772
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 2a0e1_00001
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.394082563304156 | Iter 2.000: -1.5467039808273315 | Iter 1.000: -1.8333213791951537
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.41509 |     0.5337 |                    5 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00002 | TERMINATED |                 |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00004 | TERMINATED |                 |           16 |   16 |   16 | 0.00930339  | 1.39235 |     0.5245 |                   10 |
    | DEFAULT_2a0e1_00005 | TERMINATED |                 |            2 |  128 |   16 | 0.00221886  | 1.63912 |     0.402  |                    2 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1488)[0m [6,  2000] loss: 1.196
    [2m[36m(pid=1488)[0m [6,  4000] loss: 0.614
    [2m[36m(pid=1488)[0m [6,  6000] loss: 0.416
    [2m[36m(pid=1488)[0m [6,  8000] loss: 0.308
    [2m[36m(pid=1488)[0m [6, 10000] loss: 0.253
    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.5371
      date: 2021-09-27_19-26-59
      done: false
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 6
      loss: 1.3617745132893324
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 308.29523158073425
      time_this_iter_s: 47.34918165206909
      time_total_s: 308.29523158073425
      timestamp: 1632770819
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 2a0e1_00001
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.394082563304156 | Iter 2.000: -1.5467039808273315 | Iter 1.000: -1.8333213791951537
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.36177 |     0.5371 |                    6 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00002 | TERMINATED |                 |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00004 | TERMINATED |                 |           16 |   16 |   16 | 0.00930339  | 1.39235 |     0.5245 |                   10 |
    | DEFAULT_2a0e1_00005 | TERMINATED |                 |            2 |  128 |   16 | 0.00221886  | 1.63912 |     0.402  |                    2 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1488)[0m [7,  2000] loss: 1.181
    [2m[36m(pid=1488)[0m [7,  4000] loss: 0.608
    [2m[36m(pid=1488)[0m [7,  6000] loss: 0.410
    [2m[36m(pid=1488)[0m [7,  8000] loss: 0.306
    [2m[36m(pid=1488)[0m [7, 10000] loss: 0.253
    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.5428
      date: 2021-09-27_19-27-46
      done: false
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 7
      loss: 1.4041490093529225
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 354.7536635398865
      time_this_iter_s: 46.45843195915222
      time_total_s: 354.7536635398865
      timestamp: 1632770866
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 2a0e1_00001
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.3964984920024872 | Iter 4.000: -1.394082563304156 | Iter 2.000: -1.5467039808273315 | Iter 1.000: -1.8333213791951537
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.40415 |     0.5428 |                    7 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00002 | TERMINATED |                 |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00004 | TERMINATED |                 |           16 |   16 |   16 | 0.00930339  | 1.39235 |     0.5245 |                   10 |
    | DEFAULT_2a0e1_00005 | TERMINATED |                 |            2 |  128 |   16 | 0.00221886  | 1.63912 |     0.402  |                    2 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1488)[0m [8,  2000] loss: 1.137
    [2m[36m(pid=1488)[0m [8,  4000] loss: 0.607
    [2m[36m(pid=1488)[0m [8,  6000] loss: 0.411
    [2m[36m(pid=1488)[0m [8,  8000] loss: 0.308
    [2m[36m(pid=1488)[0m [8, 10000] loss: 0.250
    Result for DEFAULT_2a0e1_00001:
      accuracy: 0.5314
      date: 2021-09-27_19-28-33
      done: true
      experiment_id: 5d5c4888558e4360b498ce429e298ea5
      hostname: a8f4394d0f82
      iterations_since_restore: 8
      loss: 1.4115734626987948
      node_ip: 172.17.0.2
      pid: 1488
      should_checkpoint: true
      time_since_restore: 401.52204847335815
      time_this_iter_s: 46.76838493347168
      time_total_s: 401.52204847335815
      timestamp: 1632770913
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 2a0e1_00001
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.404035977350641 | Iter 4.000: -1.394082563304156 | Iter 2.000: -1.5467039808273315 | Iter 1.000: -1.8333213791951537
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00001 | RUNNING    | 172.17.0.2:1488 |            4 |  128 |  256 | 0.00299773  | 1.41157 |     0.5314 |                    8 |
    | DEFAULT_2a0e1_00000 | TERMINATED |                 |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00002 | TERMINATED |                 |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |                 |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00004 | TERMINATED |                 |           16 |   16 |   16 | 0.00930339  | 1.39235 |     0.5245 |                   10 |
    | DEFAULT_2a0e1_00005 | TERMINATED |                 |            2 |  128 |   16 | 0.00221886  | 1.63912 |     0.402  |                    2 |
    | DEFAULT_2a0e1_00006 | TERMINATED |                 |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |                 |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |                 |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |                 |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    == Status ==
    Memory usage on this node: 3.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.404035977350641 | Iter 4.000: -1.394082563304156 | Iter 2.000: -1.5467039808273315 | Iter 1.000: -1.8333213791951537
    Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-09-27_19-21-50
    Number of trials: 10/10 (10 TERMINATED)
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_2a0e1_00000 | TERMINATED |       |           16 |  128 |   32 | 0.0147561   | 1.5467  |     0.4498 |                    2 |
    | DEFAULT_2a0e1_00001 | TERMINATED |       |            4 |  128 |  256 | 0.00299773  | 1.41157 |     0.5314 |                    8 |
    | DEFAULT_2a0e1_00002 | TERMINATED |       |            2 |    4 |    4 | 0.00054935  | 1.59743 |     0.3902 |                    2 |
    | DEFAULT_2a0e1_00003 | TERMINATED |       |            4 |  128 |   16 | 0.0157397   | 2.3194  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00004 | TERMINATED |       |           16 |   16 |   16 | 0.00930339  | 1.39235 |     0.5245 |                   10 |
    | DEFAULT_2a0e1_00005 | TERMINATED |       |            2 |  128 |   16 | 0.00221886  | 1.63912 |     0.402  |                    2 |
    | DEFAULT_2a0e1_00006 | TERMINATED |       |            4 |   64 |   32 | 0.0359852   | 2.3211  |     0.1035 |                    1 |
    | DEFAULT_2a0e1_00007 | TERMINATED |       |            4 |  128 |    4 | 0.000369892 | 1.95622 |     0.2397 |                    1 |
    | DEFAULT_2a0e1_00008 | TERMINATED |       |            2 |    4 |  128 | 0.000102931 | 1.94026 |     0.2751 |                    1 |
    | DEFAULT_2a0e1_00009 | TERMINATED |       |            4 |  256 |   16 | 0.0430959   | 2.31718 |     0.0965 |                    1 |
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


    Best trial config: {'l1': 16, 'l2': 16, 'lr': 0.0093033896483631, 'batch_size': 16}
    Best trial final validation loss: 1.3923472019195557
    Best trial final validation accuracy: 0.5245
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5285


If you run the code, an example output could look like this:

::

    Number of trials: 10 (10 TERMINATED)
    +-----+------+------+-------------+--------------+---------+------------+--------------------+
    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |
    |-----+------+------+-------------+--------------+---------+------------+--------------------|
    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |
    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |
    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |
    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |
    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |
    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |
    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |
    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |
    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |
    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |
    +-----+------+------+-------------+--------------+---------+------------+--------------------+


    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}
    Best trial final validation loss: 1.181501
    Best trial final validation accuracy: 0.5836
    Best trial test set accuracy: 0.5806

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 7 minutes  5.936 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
