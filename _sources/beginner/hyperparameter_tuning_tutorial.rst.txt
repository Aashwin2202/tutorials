.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:


.. code-block:: default

    from functools import partial
    import numpy as np
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.tune import CLIReporter
    from ray.tune.schedulers import ASHAScheduler







Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.


.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform)

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform)

        return trainset, testset







Configurable neural network
---------------------------
We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:


.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(-1, 16 * 5 * 5)
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x







The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.
As you can guess, the ``config`` parameter will receive the hyperparameters we would like to
train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies
the directory where we load and store the data, so multiple runs can share the same data source.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    if checkpoint_dir:
        model_state, optimizer_state = torch.load(
            os.path.join(checkpoint_dir, "checkpoint"))
        net.load_state_dict(model_state)
        optimizer.load_state_dict(optimizer_state)

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    with tune.checkpoint_dir(epoch) as checkpoint_dir:
        path = os.path.join(checkpoint_dir, "checkpoint")
        torch.save((net.state_dict(), optimizer.state_dict()), path)

    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:


.. code-block:: default



    def train_cifar(config, checkpoint_dir=None, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        if checkpoint_dir:
            model_state, optimizer_state = torch.load(
                os.path.join(checkpoint_dir, "checkpoint"))
            net.load_state_dict(model_state)
            optimizer.load_state_dict(optimizer_state)

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs])

        trainloader = torch.utils.data.DataLoader(
            train_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)
        valloader = torch.utils.data.DataLoader(
            val_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)

        for epoch in range(10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print("[%d, %5d] loss: %.3f" % (epoch + 1, i + 1,
                                                    running_loss / epoch_steps))
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            with tune.checkpoint_dir(epoch) as checkpoint_dir:
                path = os.path.join(checkpoint_dir, "checkpoint")
                torch.save((net.state_dict(), optimizer.state_dict()), path)

            tune.report(loss=(val_loss / val_steps), accuracy=correct / total)
        print("Finished Training")







As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:


.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2)

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total







The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.sample_from()`` function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:


.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16])
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2)
        reporter = CLIReporter(
            # parameter_columns=["l1", "l2", "lr", "batch_size"],
            metric_columns=["loss", "accuracy", "training_iteration"])
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
            progress_reporter=reporter)

        best_trial = result.get_best_trial("loss", "min", "last")
        print("Best trial config: {}".format(best_trial.config))
        print("Best trial final validation loss: {}".format(
            best_trial.last_result["loss"]))
        print("Best trial final validation accuracy: {}".format(
            best_trial.last_result["accuracy"]))

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint_dir = best_trial.checkpoint.value
        model_state, optimizer_state = torch.load(os.path.join(
            best_checkpoint_dir, "checkpoint"))
        best_trained_model.load_state_dict(model_state)

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (10 PENDING)
    +---------------------+----------+-------+--------------+------+------+-------------+
    | Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |
    |---------------------+----------+-------+--------------+------+------+-------------|
    | DEFAULT_ec225_00000 | PENDING  |       |           16 |    4 |   32 | 0.0392819   |
    | DEFAULT_ec225_00001 | PENDING  |       |            2 |   32 |   16 | 0.0966672   |
    | DEFAULT_ec225_00002 | PENDING  |       |           16 |   64 |    8 | 0.00063824  |
    | DEFAULT_ec225_00003 | PENDING  |       |            2 |   32 |    8 | 0.0162861   |
    | DEFAULT_ec225_00004 | PENDING  |       |            4 |   32 |  256 | 0.00895859  |
    | DEFAULT_ec225_00005 | PENDING  |       |           16 |  128 |   16 | 0.0657861   |
    | DEFAULT_ec225_00006 | PENDING  |       |            2 |    4 |   64 | 0.00161879  |
    | DEFAULT_ec225_00007 | PENDING  |       |           16 |    8 |    4 | 0.0519303   |
    | DEFAULT_ec225_00008 | PENDING  |       |           16 |    8 |   16 | 0.000662847 |
    | DEFAULT_ec225_00009 | PENDING  |       |            4 |  256 |  256 | 0.000596536 |
    +---------------------+----------+-------+--------------+------+------+-------------+


    [2m[36m(pid=1469)[0m Files already downloaded and verified
    [2m[36m(pid=1468)[0m Files already downloaded and verified
    [2m[36m(pid=1413)[0m Files already downloaded and verified
    [2m[36m(pid=1470)[0m Files already downloaded and verified
    [2m[36m(pid=1475)[0m Files already downloaded and verified
    [2m[36m(pid=1479)[0m Files already downloaded and verified
    [2m[36m(pid=1477)[0m Files already downloaded and verified
    [2m[36m(pid=1474)[0m Files already downloaded and verified
    [2m[36m(pid=1472)[0m Files already downloaded and verified
    [2m[36m(pid=1434)[0m Files already downloaded and verified
    [2m[36m(pid=1469)[0m Files already downloaded and verified
    [2m[36m(pid=1468)[0m Files already downloaded and verified
    [2m[36m(pid=1413)[0m Files already downloaded and verified
    [2m[36m(pid=1470)[0m Files already downloaded and verified
    [2m[36m(pid=1475)[0m Files already downloaded and verified
    [2m[36m(pid=1479)[0m Files already downloaded and verified
    [2m[36m(pid=1477)[0m Files already downloaded and verified
    [2m[36m(pid=1474)[0m Files already downloaded and verified
    [2m[36m(pid=1472)[0m Files already downloaded and verified
    [2m[36m(pid=1434)[0m Files already downloaded and verified
    [2m[36m(pid=1470)[0m [1,  2000] loss: 2.265
    [2m[36m(pid=1413)[0m [1,  2000] loss: 2.320
    [2m[36m(pid=1469)[0m [1,  2000] loss: 2.091
    [2m[36m(pid=1468)[0m [1,  2000] loss: 2.414
    [2m[36m(pid=1477)[0m [1,  2000] loss: 2.223
    [2m[36m(pid=1475)[0m [1,  2000] loss: 2.263
    [2m[36m(pid=1434)[0m [1,  2000] loss: 2.282
    [2m[36m(pid=1474)[0m [1,  2000] loss: 2.254
    [2m[36m(pid=1472)[0m [1,  2000] loss: 2.281
    [2m[36m(pid=1479)[0m [1,  2000] loss: 2.229
    [2m[36m(pid=1470)[0m [1,  4000] loss: 1.029
    [2m[36m(pid=1413)[0m [1,  4000] loss: 1.162
    [2m[36m(pid=1468)[0m [1,  4000] loss: 1.202
    [2m[36m(pid=1469)[0m [1,  4000] loss: 0.989
    Result for DEFAULT_ec225_00008:
      accuracy: 0.2507
      date: 2021-07-27_21-45-42
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 2.0448969118118288
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 27.859236240386963
      time_this_iter_s: 27.859236240386963
      time_total_s: 27.859236240386963
      timestamp: 1627422342
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 9.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0448969118118288
    Resources requested: 20.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+-------------+--------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+-------------+--------+------------+----------------------|
    | DEFAULT_ec225_00000 | RUNNING  |                 |           16 |    4 |   32 | 0.0392819   |        |            |                      |
    | DEFAULT_ec225_00001 | RUNNING  |                 |            2 |   32 |   16 | 0.0966672   |        |            |                      |
    | DEFAULT_ec225_00002 | RUNNING  |                 |           16 |   64 |    8 | 0.00063824  |        |            |                      |
    | DEFAULT_ec225_00003 | RUNNING  |                 |            2 |   32 |    8 | 0.0162861   |        |            |                      |
    | DEFAULT_ec225_00004 | RUNNING  |                 |            4 |   32 |  256 | 0.00895859  |        |            |                      |
    | DEFAULT_ec225_00005 | RUNNING  |                 |           16 |  128 |   16 | 0.0657861   |        |            |                      |
    | DEFAULT_ec225_00006 | RUNNING  |                 |            2 |    4 |   64 | 0.00161879  |        |            |                      |
    | DEFAULT_ec225_00007 | RUNNING  |                 |           16 |    8 |    4 | 0.0519303   |        |            |                      |
    | DEFAULT_ec225_00008 | RUNNING  | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 2.0449 |     0.2507 |                    1 |
    | DEFAULT_ec225_00009 | RUNNING  |                 |            4 |  256 |  256 | 0.000596536 |        |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+-------------+--------+------------+----------------------+


    Result for DEFAULT_ec225_00000:
      accuracy: 0.1002
      date: 2021-07-27_21-45-42
      done: true
      experiment_id: 4f3303424a714818b3c19fc34905cbcd
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 2.306956153488159
      node_ip: 172.17.0.2
      pid: 1434
      should_checkpoint: true
      time_since_restore: 27.957403898239136
      time_this_iter_s: 27.957403898239136
      time_total_s: 27.957403898239136
      timestamp: 1627422342
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00000
  
    Result for DEFAULT_ec225_00007:
      accuracy: 0.1319
      date: 2021-07-27_21-45-42
      done: true
      experiment_id: b4ee8ea7c1cc476994de4dac3bd6f314
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 2.3072290935516357
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 28.07707691192627
      time_this_iter_s: 28.07707691192627
      time_total_s: 28.07707691192627
      timestamp: 1627422342
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00007
  
    Result for DEFAULT_ec225_00002:
      accuracy: 0.2094
      date: 2021-07-27_21-45-42
      done: false
      experiment_id: 58622aa18e134644aafa4a1a2aaaa275
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 2.1566354246139525
      node_ip: 172.17.0.2
      pid: 1472
      should_checkpoint: true
      time_since_restore: 28.327509880065918
      time_this_iter_s: 28.327509880065918
      time_total_s: 28.327509880065918
      timestamp: 1627422342
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00002
  
    Result for DEFAULT_ec225_00005:
      accuracy: 0.1207
      date: 2021-07-27_21-45-43
      done: true
      experiment_id: 90ea55e903e440b8983ac5e6f00a4a83
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 2.282001222419739
      node_ip: 172.17.0.2
      pid: 1479
      should_checkpoint: true
      time_since_restore: 29.144522190093994
      time_this_iter_s: 29.144522190093994
      time_total_s: 29.144522190093994
      timestamp: 1627422343
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00005
  
    [2m[36m(pid=1477)[0m [1,  4000] loss: 0.978
    [2m[36m(pid=1470)[0m [1,  6000] loss: 0.658
    [2m[36m(pid=1468)[0m [1,  6000] loss: 0.805
    [2m[36m(pid=1413)[0m [1,  6000] loss: 0.773
    [2m[36m(pid=1469)[0m [1,  6000] loss: 0.648
    [2m[36m(pid=1477)[0m [1,  6000] loss: 0.580
    [2m[36m(pid=1475)[0m [2,  2000] loss: 1.929
    [2m[36m(pid=1470)[0m [1,  8000] loss: 0.483
    [2m[36m(pid=1472)[0m [2,  2000] loss: 2.071
    [2m[36m(pid=1413)[0m [1,  8000] loss: 0.580
    [2m[36m(pid=1468)[0m [1,  8000] loss: 0.601
    [2m[36m(pid=1469)[0m [1,  8000] loss: 0.485
    Result for DEFAULT_ec225_00008:
      accuracy: 0.3862
      date: 2021-07-27_21-46-02
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 2
      loss: 1.6863834060668945
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 47.64919567108154
      time_this_iter_s: 19.78995943069458
      time_total_s: 47.64919567108154
      timestamp: 1627422362
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 8.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.282001222419739
    Resources requested: 14.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_0_06def9b340883e2f67700bc58ab0d1e2, 0.0/2.0 CPU_group_0_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_0_7294553119e3b2e5aea41c8105576967, 0.0/2.0 CPU_group_7294553119e3b2e5aea41c8105576967, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_5fa9813aa45aaf011d6aa55ceefe4459, 0.0/2.0 CPU_group_307d9503ec672c1281219b33a1f52eba, 0.0/2.0 CPU_group_06def9b340883e2f67700bc58ab0d1e2, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_307d9503ec672c1281219b33a1f52eba, 0.0/2.0 CPU_group_0_5fa9813aa45aaf011d6aa55ceefe4459, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0addf370d419a77b9f8faa1e950e559e)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00001 | RUNNING    |                 |            2 |   32 |   16 | 0.0966672   |         |            |                      |
    | DEFAULT_ec225_00002 | RUNNING    | 172.17.0.2:1472 |           16 |   64 |    8 | 0.00063824  | 2.15664 |     0.2094 |                    1 |
    | DEFAULT_ec225_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.0162861   |         |            |                      |
    | DEFAULT_ec225_00004 | RUNNING    |                 |            4 |   32 |  256 | 0.00895859  |         |            |                      |
    | DEFAULT_ec225_00006 | RUNNING    |                 |            2 |    4 |   64 | 0.00161879  |         |            |                      |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.68638 |     0.3862 |                    2 |
    | DEFAULT_ec225_00009 | RUNNING    |                 |            4 |  256 |  256 | 0.000596536 |         |            |                      |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_ec225_00002:
      accuracy: 0.2736
      date: 2021-07-27_21-46-03
      done: true
      experiment_id: 58622aa18e134644aafa4a1a2aaaa275
      hostname: 6f533d9a4957
      iterations_since_restore: 2
      loss: 1.9306462245941163
      node_ip: 172.17.0.2
      pid: 1472
      should_checkpoint: true
      time_since_restore: 48.4129376411438
      time_this_iter_s: 20.08542776107788
      time_total_s: 48.4129376411438
      timestamp: 1627422363
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: ec225_00002
  
    [2m[36m(pid=1477)[0m [1,  8000] loss: 0.414
    [2m[36m(pid=1470)[0m [1, 10000] loss: 0.370
    [2m[36m(pid=1468)[0m [1, 10000] loss: 0.483
    [2m[36m(pid=1413)[0m [1, 10000] loss: 0.464
    [2m[36m(pid=1469)[0m [1, 10000] loss: 0.387
    [2m[36m(pid=1470)[0m [1, 12000] loss: 0.295
    [2m[36m(pid=1477)[0m [1, 10000] loss: 0.312
    Result for DEFAULT_ec225_00004:
      accuracy: 0.2738
      date: 2021-07-27_21-46-15
      done: false
      experiment_id: aac59e27827241e1b69ccc4f64a2d25f
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 1.8878541790008545
      node_ip: 172.17.0.2
      pid: 1469
      should_checkpoint: true
      time_since_restore: 60.435622215270996
      time_this_iter_s: 60.435622215270996
      time_total_s: 60.435622215270996
      timestamp: 1627422375
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00004
  
    == Status ==
    Memory usage on this node: 7.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8085148153305055 | Iter 1.000: -2.2193183235168457
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_307d9503ec672c1281219b33a1f52eba, 0.0/2.0 CPU_group_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_307d9503ec672c1281219b33a1f52eba, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_0_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00001 | RUNNING    |                 |            2 |   32 |   16 | 0.0966672   |         |            |                      |
    | DEFAULT_ec225_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.0162861   |         |            |                      |
    | DEFAULT_ec225_00004 | RUNNING    | 172.17.0.2:1469 |            4 |   32 |  256 | 0.00895859  | 1.88785 |     0.2738 |                    1 |
    | DEFAULT_ec225_00006 | RUNNING    |                 |            2 |    4 |   64 | 0.00161879  |         |            |                      |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.68638 |     0.3862 |                    2 |
    | DEFAULT_ec225_00009 | RUNNING    |                 |            4 |  256 |  256 | 0.000596536 |         |            |                      |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1468)[0m [1, 12000] loss: 0.401
    [2m[36m(pid=1413)[0m [1, 12000] loss: 0.387
    [2m[36m(pid=1475)[0m [3,  2000] loss: 1.633
    [2m[36m(pid=1470)[0m [1, 14000] loss: 0.251
    Result for DEFAULT_ec225_00008:
      accuracy: 0.4306
      date: 2021-07-27_21-46-21
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 3
      loss: 1.5567559901237489
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 66.86459755897522
      time_this_iter_s: 19.215401887893677
      time_total_s: 66.86459755897522
      timestamp: 1627422381
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 7.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8085148153305055 | Iter 1.000: -2.2193183235168457
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_0_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_5c7520edf1599934802f0f4c84aec614)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00001 | RUNNING    |                 |            2 |   32 |   16 | 0.0966672   |         |            |                      |
    | DEFAULT_ec225_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.0162861   |         |            |                      |
    | DEFAULT_ec225_00004 | RUNNING    | 172.17.0.2:1469 |            4 |   32 |  256 | 0.00895859  | 1.88785 |     0.2738 |                    1 |
    | DEFAULT_ec225_00006 | RUNNING    |                 |            2 |    4 |   64 | 0.00161879  |         |            |                      |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.55676 |     0.4306 |                    3 |
    | DEFAULT_ec225_00009 | RUNNING    |                 |            4 |  256 |  256 | 0.000596536 |         |            |                      |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_ec225_00009:
      accuracy: 0.4512
      date: 2021-07-27_21-46-21
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 1.5047615968585015
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 66.79453134536743
      time_this_iter_s: 66.79453134536743
      time_total_s: 66.79453134536743
      timestamp: 1627422381
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00009
  
    [2m[36m(pid=1468)[0m [1, 14000] loss: 0.345
    [2m[36m(pid=1413)[0m [1, 14000] loss: 0.331
    [2m[36m(pid=1469)[0m [2,  2000] loss: 1.945
    [2m[36m(pid=1470)[0m [1, 16000] loss: 0.216
    [2m[36m(pid=1477)[0m [2,  2000] loss: 1.504
    [2m[36m(pid=1468)[0m [1, 16000] loss: 0.302
    [2m[36m(pid=1413)[0m [1, 16000] loss: 0.290
    [2m[36m(pid=1469)[0m [2,  4000] loss: 0.970
    [2m[36m(pid=1475)[0m [4,  2000] loss: 1.533
    [2m[36m(pid=1470)[0m [1, 18000] loss: 0.192
    [2m[36m(pid=1468)[0m [1, 18000] loss: 0.268
    Result for DEFAULT_ec225_00008:
      accuracy: 0.4635
      date: 2021-07-27_21-46-40
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 4
      loss: 1.4866407531738282
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 85.97314691543579
      time_this_iter_s: 19.10854935646057
      time_total_s: 85.97314691543579
      timestamp: 1627422400
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 7.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.8085148153305055 | Iter 1.000: -2.1566354246139525
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_0_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_5c7520edf1599934802f0f4c84aec614)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00001 | RUNNING    |                 |            2 |   32 |   16 | 0.0966672   |         |            |                      |
    | DEFAULT_ec225_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.0162861   |         |            |                      |
    | DEFAULT_ec225_00004 | RUNNING    | 172.17.0.2:1469 |            4 |   32 |  256 | 0.00895859  | 1.88785 |     0.2738 |                    1 |
    | DEFAULT_ec225_00006 | RUNNING    |                 |            2 |    4 |   64 | 0.00161879  |         |            |                      |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.48664 |     0.4635 |                    4 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.50476 |     0.4512 |                    1 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1413)[0m [1, 18000] loss: 0.258
    [2m[36m(pid=1477)[0m [2,  4000] loss: 0.726
    [2m[36m(pid=1469)[0m [2,  6000] loss: 0.655
    [2m[36m(pid=1470)[0m [1, 20000] loss: 0.173
    [2m[36m(pid=1468)[0m [1, 20000] loss: 0.240
    [2m[36m(pid=1413)[0m [1, 20000] loss: 0.232
    [2m[36m(pid=1469)[0m [2,  8000] loss: 0.492
    [2m[36m(pid=1477)[0m [2,  6000] loss: 0.473
    [2m[36m(pid=1475)[0m [5,  2000] loss: 1.458
    Result for DEFAULT_ec225_00006:
      accuracy: 0.3757
      date: 2021-07-27_21-46-56
      done: false
      experiment_id: e4daf37b3b5a4ef7897075bfcc34ed21
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 1.634653470480442
      node_ip: 172.17.0.2
      pid: 1470
      should_checkpoint: true
      time_since_restore: 101.43551635742188
      time_this_iter_s: 101.43551635742188
      time_total_s: 101.43551635742188
      timestamp: 1627422416
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00006
  
    == Status ==
    Memory usage on this node: 7.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.8085148153305055 | Iter 1.000: -2.100766168212891
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_0_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00001 | RUNNING    |                 |            2 |   32 |   16 | 0.0966672   |         |            |                      |
    | DEFAULT_ec225_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.0162861   |         |            |                      |
    | DEFAULT_ec225_00004 | RUNNING    | 172.17.0.2:1469 |            4 |   32 |  256 | 0.00895859  | 1.88785 |     0.2738 |                    1 |
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.48664 |     0.4635 |                    4 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.50476 |     0.4512 |                    1 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_ec225_00008:
      accuracy: 0.4861
      date: 2021-07-27_21-47-00
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 5
      loss: 1.4251554502487183
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 105.38003087043762
      time_this_iter_s: 19.40688395500183
      time_total_s: 105.38003087043762
      timestamp: 1627422420
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: ec225_00008
  
    [2m[36m(pid=1469)[0m [2, 10000] loss: 0.390
    [2m[36m(pid=1477)[0m [2,  8000] loss: 0.347
    Result for DEFAULT_ec225_00001:
      accuracy: 0.0992
      date: 2021-07-27_21-47-01
      done: true
      experiment_id: 64d930a2ca21478094a7effd321c05f9
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 2.4613506103277207
      node_ip: 172.17.0.2
      pid: 1468
      should_checkpoint: true
      time_since_restore: 106.7495801448822
      time_this_iter_s: 106.7495801448822
      time_total_s: 106.7495801448822
      timestamp: 1627422421
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00001
  
    == Status ==
    Memory usage on this node: 7.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.8085148153305055 | Iter 1.000: -2.1566354246139525
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_0_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00001 | RUNNING    | 172.17.0.2:1468 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.0162861   |         |            |                      |
    | DEFAULT_ec225_00004 | RUNNING    | 172.17.0.2:1469 |            4 |   32 |  256 | 0.00895859  | 1.88785 |     0.2738 |                    1 |
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.42516 |     0.4861 |                    5 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.50476 |     0.4512 |                    1 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_ec225_00003:
      accuracy: 0.1015
      date: 2021-07-27_21-47-01
      done: true
      experiment_id: 4c2b73a74d834f459e965b0f9bedf253
      hostname: 6f533d9a4957
      iterations_since_restore: 1
      loss: 2.3205570737600327
      node_ip: 172.17.0.2
      pid: 1413
      should_checkpoint: true
      time_since_restore: 107.00259065628052
      time_this_iter_s: 107.00259065628052
      time_total_s: 107.00259065628052
      timestamp: 1627422421
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: ec225_00003
  
    [2m[36m(pid=1470)[0m [2,  2000] loss: 1.678
    Result for DEFAULT_ec225_00004:
      accuracy: 0.2859
      date: 2021-07-27_21-47-06
      done: true
      experiment_id: aac59e27827241e1b69ccc4f64a2d25f
      hostname: 6f533d9a4957
      iterations_since_restore: 2
      loss: 1.9095778154850007
      node_ip: 172.17.0.2
      pid: 1469
      should_checkpoint: true
      time_since_restore: 111.75986766815186
      time_this_iter_s: 51.32424545288086
      time_total_s: 111.75986766815186
      timestamp: 1627422426
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: ec225_00004
  
    == Status ==
    Memory usage on this node: 6.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.9095778154850007 | Iter 1.000: -2.2193183235168457
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_0_0addf370d419a77b9f8faa1e950e559e, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_5c7520edf1599934802f0f4c84aec614, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00004 | RUNNING    | 172.17.0.2:1469 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.42516 |     0.4861 |                    5 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.50476 |     0.4512 |                    1 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1477)[0m [2, 10000] loss: 0.273
    [2m[36m(pid=1470)[0m [2,  4000] loss: 0.838
    [2m[36m(pid=1475)[0m [6,  2000] loss: 1.378
    Result for DEFAULT_ec225_00009:
      accuracy: 0.5173
      date: 2021-07-27_21-47-16
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 2
      loss: 1.3562394530802966
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 121.39140057563782
      time_this_iter_s: 54.596869230270386
      time_total_s: 121.39140057563782
      timestamp: 1627422436
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 5.8/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.7979806107759475 | Iter 1.000: -2.2193183235168457
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_e56be96d9556f85a44ebfea3ea819eb2, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_e56be96d9556f85a44ebfea3ea819eb2, 0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.42516 |     0.4861 |                    5 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.35624 |     0.5173 |                    2 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_ec225_00008:
      accuracy: 0.5163
      date: 2021-07-27_21-47-18
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 6
      loss: 1.336819828224182
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 123.49892330169678
      time_this_iter_s: 18.118892431259155
      time_total_s: 123.49892330169678
      timestamp: 1627422438
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: ec225_00008
  
    [2m[36m(pid=1470)[0m [2,  6000] loss: 0.552
    [2m[36m(pid=1477)[0m [3,  2000] loss: 1.299
    [2m[36m(pid=1470)[0m [2,  8000] loss: 0.417
    [2m[36m(pid=1475)[0m [7,  2000] loss: 1.321
    [2m[36m(pid=1470)[0m [2, 10000] loss: 0.335
    [2m[36m(pid=1477)[0m [3,  4000] loss: 0.639
    Result for DEFAULT_ec225_00008:
      accuracy: 0.5272
      date: 2021-07-27_21-47-36
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 7
      loss: 1.3143555951118469
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 141.8019278049469
      time_this_iter_s: 18.303004503250122
      time_total_s: 141.8019278049469
      timestamp: 1627422456
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.7979806107759475 | Iter 1.000: -2.2193183235168457
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.31436 |     0.5272 |                    7 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.35624 |     0.5173 |                    2 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1470)[0m [2, 12000] loss: 0.276
    [2m[36m(pid=1477)[0m [3,  6000] loss: 0.423
    [2m[36m(pid=1470)[0m [2, 14000] loss: 0.237
    [2m[36m(pid=1475)[0m [8,  2000] loss: 1.276
    [2m[36m(pid=1477)[0m [3,  8000] loss: 0.310
    Result for DEFAULT_ec225_00008:
      accuracy: 0.5331
      date: 2021-07-27_21-47-54
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 8
      loss: 1.2980317111968993
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 159.9089117050171
      time_this_iter_s: 18.10698390007019
      time_total_s: 159.9089117050171
      timestamp: 1627422474
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.7979806107759475 | Iter 1.000: -2.2193183235168457
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.29803 |     0.5331 |                    8 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.35624 |     0.5173 |                    2 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1470)[0m [2, 16000] loss: 0.208
    [2m[36m(pid=1477)[0m [3, 10000] loss: 0.249
    [2m[36m(pid=1470)[0m [2, 18000] loss: 0.187
    [2m[36m(pid=1475)[0m [9,  2000] loss: 1.238
    Result for DEFAULT_ec225_00009:
      accuracy: 0.5701
      date: 2021-07-27_21-48-07
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 3
      loss: 1.2128808798015118
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 172.7069971561432
      time_this_iter_s: 51.31559658050537
      time_total_s: 172.7069971561432
      timestamp: 1627422487
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 5.8/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.7979806107759475 | Iter 1.000: -2.2193183235168457
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.29803 |     0.5331 |                    8 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.21288 |     0.5701 |                    3 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1470)[0m [2, 20000] loss: 0.164
    Result for DEFAULT_ec225_00008:
      accuracy: 0.5493
      date: 2021-07-27_21-48-12
      done: false
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 9
      loss: 1.2536585591316223
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 178.16918420791626
      time_this_iter_s: 18.26027250289917
      time_total_s: 178.16918420791626
      timestamp: 1627422492
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 5.8/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.7979806107759475 | Iter 1.000: -2.2193183235168457
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.63465 |     0.3757 |                    1 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.25366 |     0.5493 |                    9 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.21288 |     0.5701 |                    3 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1477)[0m [4,  2000] loss: 1.161
    Result for DEFAULT_ec225_00006:
      accuracy: 0.4065
      date: 2021-07-27_21-48-20
      done: false
      experiment_id: e4daf37b3b5a4ef7897075bfcc34ed21
      hostname: 6f533d9a4957
      iterations_since_restore: 2
      loss: 1.654973203929531
      node_ip: 172.17.0.2
      pid: 1470
      should_checkpoint: true
      time_since_restore: 185.75968503952026
      time_this_iter_s: 84.32416868209839
      time_total_s: 185.75968503952026
      timestamp: 1627422500
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: ec225_00006
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.65497 |     0.4065 |                    2 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.25366 |     0.5493 |                    9 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.21288 |     0.5701 |                    3 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1475)[0m [10,  2000] loss: 1.219
    [2m[36m(pid=1477)[0m [4,  4000] loss: 0.589
    [2m[36m(pid=1470)[0m [3,  2000] loss: 1.640
    Result for DEFAULT_ec225_00008:
      accuracy: 0.5518
      date: 2021-07-27_21-48-30
      done: true
      experiment_id: a2388360d546496da1373c34b7c74f83
      hostname: 6f533d9a4957
      iterations_since_restore: 10
      loss: 1.2352830703735351
      node_ip: 172.17.0.2
      pid: 1475
      should_checkpoint: true
      time_since_restore: 196.00239253044128
      time_this_iter_s: 17.833208322525024
      time_total_s: 196.00239253044128
      timestamp: 1627422510
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: ec225_00008
  
    == Status ==
    Memory usage on this node: 5.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.65497 |     0.4065 |                    2 |
    | DEFAULT_ec225_00008 | RUNNING    | 172.17.0.2:1475 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.21288 |     0.5701 |                    3 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1477)[0m [4,  6000] loss: 0.381
    [2m[36m(pid=1470)[0m [3,  4000] loss: 0.814
    [2m[36m(pid=1470)[0m [3,  6000] loss: 0.539
    [2m[36m(pid=1477)[0m [4,  8000] loss: 0.290
    [2m[36m(pid=1470)[0m [3,  8000] loss: 0.408
    [2m[36m(pid=1477)[0m [4, 10000] loss: 0.229
    [2m[36m(pid=1470)[0m [3, 10000] loss: 0.323
    Result for DEFAULT_ec225_00009:
      accuracy: 0.5964
      date: 2021-07-27_21-48-58
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 4
      loss: 1.1619304859876634
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 223.32157516479492
      time_this_iter_s: 50.61457800865173
      time_total_s: 223.32157516479492
      timestamp: 1627422538
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 5.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.3242856195807458 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 4.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_d7130246c271eb4586e5d98b8bf28156, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.65497 |     0.4065 |                    2 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.16193 |     0.5964 |                    4 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1470)[0m [3, 12000] loss: 0.271
    [2m[36m(pid=1477)[0m [5,  2000] loss: 1.056
    [2m[36m(pid=1470)[0m [3, 14000] loss: 0.233
    [2m[36m(pid=1477)[0m [5,  4000] loss: 0.534
    [2m[36m(pid=1470)[0m [3, 16000] loss: 0.204
    [2m[36m(pid=1477)[0m [5,  6000] loss: 0.353
    [2m[36m(pid=1470)[0m [3, 18000] loss: 0.177
    [2m[36m(pid=1470)[0m [3, 20000] loss: 0.163
    [2m[36m(pid=1477)[0m [5,  8000] loss: 0.264
    [2m[36m(pid=1477)[0m [5, 10000] loss: 0.217
    Result for DEFAULT_ec225_00006:
      accuracy: 0.3909
      date: 2021-07-27_21-49-43
      done: false
      experiment_id: e4daf37b3b5a4ef7897075bfcc34ed21
      hostname: 6f533d9a4957
      iterations_since_restore: 3
      loss: 1.6416264570310712
      node_ip: 172.17.0.2
      pid: 1470
      should_checkpoint: true
      time_since_restore: 268.4230329990387
      time_this_iter_s: 82.66334795951843
      time_total_s: 268.4230329990387
      timestamp: 1627422583
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: ec225_00006
  
    == Status ==
    Memory usage on this node: 5.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.3242856195807458 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 4.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.64163 |     0.3909 |                    3 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.16193 |     0.5964 |                    4 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_ec225_00009:
      accuracy: 0.5883
      date: 2021-07-27_21-49-47
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 5
      loss: 1.1660976984515785
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 272.8560335636139
      time_this_iter_s: 49.53445839881897
      time_total_s: 272.8560335636139
      timestamp: 1627422587
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: ec225_00009
  
    [2m[36m(pid=1470)[0m [4,  2000] loss: 1.616
    [2m[36m(pid=1477)[0m [6,  2000] loss: 0.976
    [2m[36m(pid=1470)[0m [4,  4000] loss: 0.801
    [2m[36m(pid=1470)[0m [4,  6000] loss: 0.533
    [2m[36m(pid=1477)[0m [6,  4000] loss: 0.493
    [2m[36m(pid=1470)[0m [4,  8000] loss: 0.398
    [2m[36m(pid=1477)[0m [6,  6000] loss: 0.331
    [2m[36m(pid=1470)[0m [4, 10000] loss: 0.315
    [2m[36m(pid=1477)[0m [6,  8000] loss: 0.246
    [2m[36m(pid=1470)[0m [4, 12000] loss: 0.267
    [2m[36m(pid=1477)[0m [6, 10000] loss: 0.196
    [2m[36m(pid=1470)[0m [4, 14000] loss: 0.233
    Result for DEFAULT_ec225_00009:
      accuracy: 0.62
      date: 2021-07-27_21-50-37
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 6
      loss: 1.0990315326437354
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 322.438444852829
      time_this_iter_s: 49.58241128921509
      time_total_s: 322.438444852829
      timestamp: 1627422637
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 5.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.3242856195807458 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 4.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.64163 |     0.3909 |                    3 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.09903 |     0.62   |                    6 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1470)[0m [4, 16000] loss: 0.201
    [2m[36m(pid=1477)[0m [7,  2000] loss: 0.883
    [2m[36m(pid=1470)[0m [4, 18000] loss: 0.176
    [2m[36m(pid=1470)[0m [4, 20000] loss: 0.162
    [2m[36m(pid=1477)[0m [7,  4000] loss: 0.450
    [2m[36m(pid=1477)[0m [7,  6000] loss: 0.300
    Result for DEFAULT_ec225_00006:
      accuracy: 0.4185
      date: 2021-07-27_21-51-04
      done: true
      experiment_id: e4daf37b3b5a4ef7897075bfcc34ed21
      hostname: 6f533d9a4957
      iterations_since_restore: 4
      loss: 1.5402509211495519
      node_ip: 172.17.0.2
      pid: 1470
      should_checkpoint: true
      time_since_restore: 350.0648260116577
      time_this_iter_s: 81.64179301261902
      time_total_s: 350.0648260116577
      timestamp: 1627422664
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: ec225_00006
  
    == Status ==
    Memory usage on this node: 5.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 4.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00006 | RUNNING    | 172.17.0.2:1470 |            2 |    4 |   64 | 0.00161879  | 1.54025 |     0.4185 |                    4 |
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.09903 |     0.62   |                    6 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1477)[0m [7,  8000] loss: 0.233
    [2m[36m(pid=1477)[0m [7, 10000] loss: 0.188
    Result for DEFAULT_ec225_00009:
      accuracy: 0.6249
      date: 2021-07-27_21-51-26
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 7
      loss: 1.1079832498148083
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 372.0105628967285
      time_this_iter_s: 49.572118043899536
      time_total_s: 372.0105628967285
      timestamp: 1627422686
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2980317111968993 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_802438422f3edf94c7471abfecad2d4b, 0.0/2.0 CPU_group_0_802438422f3edf94c7471abfecad2d4b)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.10798 |     0.6249 |                    7 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00006 | TERMINATED |                 |            2 |    4 |   64 | 0.00161879  | 1.54025 |     0.4185 |                    4 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1477)[0m [8,  2000] loss: 0.812
    [2m[36m(pid=1477)[0m [8,  4000] loss: 0.414
    [2m[36m(pid=1477)[0m [8,  6000] loss: 0.282
    [2m[36m(pid=1477)[0m [8,  8000] loss: 0.213
    [2m[36m(pid=1477)[0m [8, 10000] loss: 0.174
    Result for DEFAULT_ec225_00009:
      accuracy: 0.6325
      date: 2021-07-27_21-52-15
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 8
      loss: 1.0772747973307968
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 420.56029987335205
      time_this_iter_s: 48.549736976623535
      time_total_s: 420.56029987335205
      timestamp: 1627422735
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.187653254263848 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.07727 |     0.6325 |                    8 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00006 | TERMINATED |                 |            2 |    4 |   64 | 0.00161879  | 1.54025 |     0.4185 |                    4 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1477)[0m [9,  2000] loss: 0.723
    [2m[36m(pid=1477)[0m [9,  4000] loss: 0.382
    [2m[36m(pid=1477)[0m [9,  6000] loss: 0.265
    [2m[36m(pid=1477)[0m [9,  8000] loss: 0.199
    [2m[36m(pid=1477)[0m [9, 10000] loss: 0.160
    Result for DEFAULT_ec225_00009:
      accuracy: 0.6292
      date: 2021-07-27_21-53-03
      done: false
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 9
      loss: 1.1211545364859514
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 468.99146246910095
      time_this_iter_s: 48.4311625957489
      time_total_s: 468.99146246910095
      timestamp: 1627422783
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.187653254263848 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.12115 |     0.6292 |                    9 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00006 | TERMINATED |                 |            2 |    4 |   64 | 0.00161879  | 1.54025 |     0.4185 |                    4 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1477)[0m [10,  2000] loss: 0.673
    [2m[36m(pid=1477)[0m [10,  4000] loss: 0.353
    [2m[36m(pid=1477)[0m [10,  6000] loss: 0.244
    [2m[36m(pid=1477)[0m [10,  8000] loss: 0.180
    [2m[36m(pid=1477)[0m [10, 10000] loss: 0.146
    Result for DEFAULT_ec225_00009:
      accuracy: 0.6336
      date: 2021-07-27_21-53-53
      done: true
      experiment_id: c63820c941ff4d4d9b8d83e5f0a5059b
      hostname: 6f533d9a4957
      iterations_since_restore: 10
      loss: 1.1315998354546726
      node_ip: 172.17.0.2
      pid: 1477
      should_checkpoint: true
      time_since_restore: 518.5333888530731
      time_this_iter_s: 49.54192638397217
      time_total_s: 518.5333888530731
      timestamp: 1627422833
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: ec225_00009
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.187653254263848 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00009 | RUNNING    | 172.17.0.2:1477 |            4 |  256 |  256 | 0.000596536 | 1.1316  |     0.6336 |                   10 |
    | DEFAULT_ec225_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |                 |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |                 |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |                 |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |                 |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00006 | TERMINATED |                 |            2 |    4 |   64 | 0.00161879  | 1.54025 |     0.4185 |                    4 |
    | DEFAULT_ec225_00007 | TERMINATED |                 |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |                 |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    == Status ==
    Memory usage on this node: 4.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.187653254263848 | Iter 4.000: -1.4866407531738282 | Iter 2.000: -1.6863834060668945 | Iter 1.000: -2.2193183235168457
    Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/220.16 GiB heap, 0.0/9.31 GiB objects (0.0/2.0 CPU_group_87761bc0debd9325565e45e122c83225, 0.0/2.0 CPU_group_0_87761bc0debd9325565e45e122c83225, 0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-07-27_21-45-12
    Number of trials: 10/10 (10 TERMINATED)
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_ec225_00000 | TERMINATED |       |           16 |    4 |   32 | 0.0392819   | 2.30696 |     0.1002 |                    1 |
    | DEFAULT_ec225_00001 | TERMINATED |       |            2 |   32 |   16 | 0.0966672   | 2.46135 |     0.0992 |                    1 |
    | DEFAULT_ec225_00002 | TERMINATED |       |           16 |   64 |    8 | 0.00063824  | 1.93065 |     0.2736 |                    2 |
    | DEFAULT_ec225_00003 | TERMINATED |       |            2 |   32 |    8 | 0.0162861   | 2.32056 |     0.1015 |                    1 |
    | DEFAULT_ec225_00004 | TERMINATED |       |            4 |   32 |  256 | 0.00895859  | 1.90958 |     0.2859 |                    2 |
    | DEFAULT_ec225_00005 | TERMINATED |       |           16 |  128 |   16 | 0.0657861   | 2.282   |     0.1207 |                    1 |
    | DEFAULT_ec225_00006 | TERMINATED |       |            2 |    4 |   64 | 0.00161879  | 1.54025 |     0.4185 |                    4 |
    | DEFAULT_ec225_00007 | TERMINATED |       |           16 |    8 |    4 | 0.0519303   | 2.30723 |     0.1319 |                    1 |
    | DEFAULT_ec225_00008 | TERMINATED |       |           16 |    8 |   16 | 0.000662847 | 1.23528 |     0.5518 |                   10 |
    | DEFAULT_ec225_00009 | TERMINATED |       |            4 |  256 |  256 | 0.000596536 | 1.1316  |     0.6336 |                   10 |
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


    Best trial config: {'l1': 256, 'l2': 256, 'lr': 0.0005965363695630573, 'batch_size': 4}
    Best trial final validation loss: 1.1315998354546726
    Best trial final validation accuracy: 0.6336
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.6269


If you run the code, an example output could look like this:

::

    Number of trials: 10 (10 TERMINATED)
    +-----+------+------+-------------+--------------+---------+------------+--------------------+
    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |
    |-----+------+------+-------------+--------------+---------+------------+--------------------|
    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |
    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |
    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |
    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |
    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |
    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |
    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |
    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |
    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |
    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |
    +-----+------+------+-------------+--------------+---------+------------+--------------------+


    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}
    Best trial final validation loss: 1.181501
    Best trial final validation accuracy: 0.5836
    Best trial test set accuracy: 0.5806

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 9 minutes  6.494 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
